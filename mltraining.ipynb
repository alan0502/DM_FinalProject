{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n",
    "import seaborn as sns\n",
    "import plotly.subplots as sp\n",
    "import plotly.express as px\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone, BaseEstimator, RegressorMixin\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from pytorch_tabnet.callbacks import Callback\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pytorch_tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Find rows where both columns have values\n",
    "conflict_rows = train[(train['PAQ_A-PAQ_A_Total'].notna()) & (train['PAQ_C-PAQ_C_Total'].notna())]\n",
    "\n",
    "# Print the number of conflicting rows\n",
    "print(f\"Number of conflict rows: {len(conflict_rows)}\")\n",
    "\n",
    "# 判斷是否存在衝突行\n",
    "\n",
    "if not conflict_rows.empty:\n",
    "\n",
    "    train = train.drop(conflict_rows.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train['PAQ_A-PAQ_A_Total'] = train['PAQ_A-PAQ_A_Total'].fillna(train['PAQ_C-PAQ_C_Total'])\n",
    "\n",
    "train['PAQ_A-Season'] = train['PAQ_A-Season'].fillna(train['PAQ_C-Season'])\n",
    "\n",
    "test['PAQ_A-PAQ_A_Total'] = test['PAQ_A-PAQ_A_Total'].fillna(test['PAQ_C-PAQ_C_Total'])\n",
    "\n",
    "test['PAQ_A-Season'] = test['PAQ_A-Season'].fillna(test['PAQ_C-Season'])\n",
    "\n",
    "\n",
    "\n",
    "# 刪除 column2\n",
    "\n",
    "train = train.drop(columns=['PAQ_C-PAQ_C_Total', 'PAQ_C-Season'])\n",
    "\n",
    "test = test.drop(columns=['PAQ_C-PAQ_C_Total', 'PAQ_C-Season'])\n",
    "\n",
    "\n",
    "\n",
    "train = train.rename(columns={'PAQ_A-Season': 'PAQ-Season'})\n",
    "\n",
    "train = train.rename(columns={'PAQ_A-PAQ_A_Total': 'PAQ-PAQ_Total'})\n",
    "\n",
    "test = test.rename(columns={'PAQ_A-Season': 'PAQ-Season'})\n",
    "\n",
    "test = test.rename(columns={'PAQ_A-PAQ_A_Total': 'PAQ-PAQ_Total'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_file(filename, dirname):\n",
    "\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "\n",
    "    ids = os.listdir(dirname)\n",
    "\n",
    "    \n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "\n",
    "    \n",
    "\n",
    "    stats, indexes = zip(*results)\n",
    "\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame(stats, columns=[f\"Stat_{i}\" for i in range(len(stats[0]))])\n",
    "\n",
    "    df['id'] = indexes\n",
    "\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ-Season',\n",
    "                'PAQ-PAQ_Total',\n",
    "                'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'PCIAT-PCIAT_Total'] \n",
    "                # change 'sii' to 'PCIAT-PCIAT_Total'\n",
    "\n",
    "SEASON_COL = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n",
    "          'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "          'PAQ-Season', 'SDS-Season', 'PreInt_EduHx-Season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "\n",
    "train = train[featuresCols]\n",
    "# removes rows from the train DataFrame where the PCIAT-PCIAT_Total column has missing values (NaN). \n",
    "train = train.dropna(subset='PCIAT-PCIAT_Total') # change 'sii' to 'PCIAT-PCIAT_Total'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def update(df):\n",
    "    global SEASON_COL\n",
    "    for c in SEASON_COL: \n",
    "        df[c] = df[c].fillna('Missing')\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "\n",
    "train = update(train)\n",
    "test = update(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "season_mapping = {'Spring': 0, 'Summer': 1, 'Fall': 2, 'Winter': 3, 'Missing': 4}\n",
    "\n",
    "for col in SEASON_COL:\n",
    "\n",
    "    train[col] = train[col].map(season_mapping)\n",
    "\n",
    "    test[col] = test[col].map(season_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from sklearn.base import clone\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# X = train.drop(['PCIAT-PCIAT_Total'], axis=1) # change 'sii' to 'PCIAT-PCIAT_Total'\n",
    "# y = train['PCIAT-PCIAT_Total'] # change 'sii' to 'PCIAT-PCIAT_Total'\n",
    "\n",
    "# # Optuna Objective Function\n",
    "# def optuna_objective(trial):\n",
    "#     # Define the hyperparameter search space\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n",
    "#         'min_child_weight': trial.suggest_float('min_child_weight', 0.01, 10.0)\n",
    "#     }\n",
    "\n",
    "#     # Model Initialization\n",
    "#     model = LGBMRegressor(random_state=42, force_col_wise=True, **params)\n",
    "#     oof_preds = np.zeros(len(y))  # Out-of-fold predictions\n",
    "\n",
    "#     # Stratified K-Fold Cross-Validation\n",
    "#     SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#     for train_idx, val_idx in SKF.split(X, y):\n",
    "#         X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#         y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "#         model.fit(X_train, y_train)\n",
    "#         oof_preds[val_idx] = model.predict(X_val)\n",
    "\n",
    "#     # Convert predictions to sii labels\n",
    "#     oof_rounded = np.vectorize(pciat_to_sii)(oof_preds)\n",
    "#     true_rounded = np.vectorize(pciat_to_sii)(y)\n",
    "\n",
    "#     # Return QWK (negative for Optuna to maximize)\n",
    "#     return quadratic_weighted_kappa(true_rounded, oof_rounded)\n",
    "\n",
    "# # Run Optuna Optimization\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(optuna_objective, n_trials=50)  # Number of trials for optimization\n",
    "\n",
    "# # Print Best Parameters and Score\n",
    "# print(f\"Best Parameters: {study.best_params}\")\n",
    "# print(f\"Best QWK Score: {study.best_value}\")\n",
    "\n",
    "# # Use Best Parameters in Final Model\n",
    "# best_params = study.best_params\n",
    "# optimized_lgb_model = LGBMRegressor(random_state=42, force_col_wise=True, **best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore Warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Import required libraries\n",
    "# import optuna\n",
    "# from xgboost import XGBRegressor\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Prepare your data\n",
    "# X = train.drop(['PCIAT-PCIAT_Total'], axis=1)  # Features\n",
    "# y = train['PCIAT-PCIAT_Total']  # Target\n",
    "\n",
    "# # Optuna Objective Function for XGBoost\n",
    "# def optuna_objective(trial):\n",
    "#     # Define the hyperparameter search space\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n",
    "#         'min_child_weight': trial.suggest_float('min_child_weight', 0.01, 10.0),\n",
    "#         'gamma': trial.suggest_float('gamma', 0.0, 5.0)  # Additional XGBoost parameter\n",
    "#     }\n",
    "\n",
    "#     # Initialize the XGBoost model\n",
    "#     model = XGBRegressor(\n",
    "#         random_state=42, \n",
    "#         enable_categorical=True,  # Enable categorical support\n",
    "#         **params)\n",
    "#     oof_preds = np.zeros(len(y))  # Out-of-fold predictions\n",
    "\n",
    "#     # Stratified K-Fold Cross-Validation\n",
    "#     SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#     for train_idx, val_idx in SKF.split(X, y):\n",
    "#         X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#         y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "#         model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='rmse', verbose=False, early_stopping_rounds=50)\n",
    "#         oof_preds[val_idx] = model.predict(X_val)\n",
    "\n",
    "#     # Convert predictions to sii labels\n",
    "#     oof_rounded = np.vectorize(pciat_to_sii)(oof_preds)\n",
    "#     true_rounded = np.vectorize(pciat_to_sii)(y)\n",
    "\n",
    "#     # Return QWK (negative for Optuna to maximize)\n",
    "#     return quadratic_weighted_kappa(true_rounded, oof_rounded)\n",
    "\n",
    "# # Run Optuna Optimization\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(optuna_objective, n_trials=50)  # Number of trials for optimization\n",
    "\n",
    "# # Print Best Parameters and Score\n",
    "# print(f\"Best Parameters for XGBoost: {study.best_params}\")\n",
    "# print(f\"Best QWK Score for XGBoost: {study.best_value}\")\n",
    "\n",
    "# # Use Best Parameters in Final Model\n",
    "# best_params = study.best_params\n",
    "# optimized_xgb_model = XGBRegressor(random_state=42, **best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Import required libraries\n",
    "# import optuna\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Prepare your data\n",
    "# X = train.drop(['PCIAT-PCIAT_Total'], axis=1)  # Features\n",
    "# y = train['PCIAT-PCIAT_Total']  # Target\n",
    "\n",
    "# # Optuna Objective Function for CatBoost\n",
    "# def optuna_objective(trial):\n",
    "#     # Define the hyperparameter search space\n",
    "#     params = {\n",
    "#         'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "#         'depth': trial.suggest_int('depth', 3, 12),\n",
    "#         'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n",
    "#         'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "#         'random_strength': trial.suggest_float('random_strength', 0.0, 10.0),\n",
    "#         'border_count': trial.suggest_int('border_count', 32, 255),  # Number of splits for categorical features\n",
    "#         'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "#     }\n",
    "\n",
    "#     # Initialize the CatBoost model\n",
    "#     model = CatBoostRegressor(\n",
    "#         random_state=42,\n",
    "#         silent=True,  # Suppress verbose output\n",
    "#         cat_features=X.select_dtypes(include=['category']).columns.tolist(),  # Identify categorical features\n",
    "#         **params\n",
    "#     )\n",
    "#     oof_preds = np.zeros(len(y))  # Out-of-fold predictions\n",
    "\n",
    "#     # Stratified K-Fold Cross-Validation\n",
    "#     SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#     for train_idx, val_idx in SKF.split(X, y):\n",
    "#         X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#         y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "#         model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50)\n",
    "#         oof_preds[val_idx] = model.predict(X_val)\n",
    "\n",
    "#     # Convert predictions to sii labels\n",
    "#     oof_rounded = np.vectorize(pciat_to_sii)(oof_preds)\n",
    "#     true_rounded = np.vectorize(pciat_to_sii)(y)\n",
    "\n",
    "#     # Return QWK (negative for Optuna to maximize)\n",
    "#     return quadratic_weighted_kappa(true_rounded, oof_rounded)\n",
    "\n",
    "# # Run Optuna Optimization\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(optuna_objective, n_trials=50)  # Number of trials for optimization\n",
    "\n",
    "# # Print Best Parameters and Score\n",
    "# print(f\"Best Parameters for CatBoost: {study.best_params}\")\n",
    "# print(f\"Best QWK Score for CatBoost: {study.best_value}\")\n",
    "\n",
    "# # Use Best Parameters in Final Model\n",
    "# best_params = study.best_params\n",
    "# optimized_cat_model = CatBoostRegressor(random_state=42, silent=True, **best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "\n",
    "def pciat_to_sii(pciat_score):\n",
    "    \"\"\"\n",
    "    Transform PCIAT-PCIAT_Total predictions into sii labels.\n",
    "    \"\"\"\n",
    "    if pciat_score <= 30:\n",
    "        return 0\n",
    "    elif pciat_score <= 49:\n",
    "        return 1\n",
    "    elif pciat_score <= 79:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    \"\"\"\n",
    "    Apply thresholds to PCIAT-PCIAT_Total predictions and map to sii labels.\n",
    "    \"\"\"\n",
    "    rounded = np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                       np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                                np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "    return rounded\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    \"\"\"\n",
    "    Evaluate QWK by mapping PCIAT-PCIAT_Total predictions to sii labels.\n",
    "    \"\"\"\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "def TrainML(model_class, test_data):\n",
    "\n",
    "    X = train.drop(['PCIAT-PCIAT_Total'], axis=1) # change 'sii' to 'PCIAT-PCIAT_Total'\n",
    "    y = train['PCIAT-PCIAT_Total'] # change 'sii' to 'PCIAT-PCIAT_Total'\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    train_S = []\n",
    "    test_S = []\n",
    "\n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float)\n",
    "    oof_rounded = np.zeros(len(y), dtype=int)\n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    print(\"Starting Cross-Validation...\")\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = np.vectorize(pciat_to_sii)(y_val_pred)  # Transform PCIAT-PCIAT_Total to sii\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(\n",
    "            np.vectorize(pciat_to_sii)(y_train),  # Map y_train to sii\n",
    "            np.vectorize(pciat_to_sii)(y_train_pred.round(0))\n",
    "        )\n",
    "        val_kappa = quadratic_weighted_kappa(\n",
    "            np.vectorize(pciat_to_sii)(y_val),\n",
    "            y_val_pred_rounded\n",
    "        )\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "\n",
    "        test_preds[:, fold] = model.predict(test_data)\n",
    "\n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "            \n",
    "\n",
    "\n",
    "    # Log fold-specific and overall QWK statistics\n",
    "    print(\"\\nFold-wise QWK Scores:\")\n",
    "    for fold_idx, (train_qwk, val_qwk) in enumerate(zip(train_S, test_S), start=1):\n",
    "        print(f\"Fold {fold_idx}: Train QWK = {train_qwk:.4f}, Validation QWK = {val_qwk:.4f}\")\n",
    "    \n",
    "    print(f\"\\nMean Train QWK --> {np.mean(train_S):.4f} ± {np.std(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f} ± {np.std(test_S):.4f}\")\n",
    "\n",
    "\n",
    "    # Map PCIAT-PCIAT_Total to sii for threshold optimization\n",
    "    sii_labels = np.vectorize(pciat_to_sii)(train['PCIAT-PCIAT_Total'])\n",
    "    \n",
    "    # Optimize thresholds using multiple methods\n",
    "    methods = ['Nelder-Mead', 'Powell', 'TNC']\n",
    "    best_result = None\n",
    "    best_thresholds = None\n",
    "    best_score = float('-inf')\n",
    "    \n",
    "    for method in methods:\n",
    "        result = minimize(evaluate_predictions,\n",
    "                          x0=[30, 49, 79],  # Initial threshold guesses\n",
    "                          args=(sii_labels, oof_non_rounded),\n",
    "                          method=method)\n",
    "        if result.success:\n",
    "            score = -result.fun\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_result = result\n",
    "                best_thresholds = result.x\n",
    "\n",
    "    print(f\"\\nBest thresholds: {best_thresholds}\")\n",
    "    print(f\"Best QWK score after optimization: {best_score:.4f}\")\n",
    "\n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, best_thresholds)\n",
    "    tKappa = quadratic_weighted_kappa(sii_labels, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tp_rounded = threshold_Rounder(tpm, best_thresholds)\n",
    "\n",
    "\n",
    "    return tp_rounded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Optimized LightGBM model\n",
    "optimized_lgb_model = LGBMRegressor(\n",
    "    n_estimators=107,\n",
    "    learning_rate=0.1370718043598246,\n",
    "    max_depth=4,\n",
    "    num_leaves=68,\n",
    "    colsample_bytree=0.7238253848440545,\n",
    "    subsample=0.5543321896833934,\n",
    "    reg_alpha=7.854917349399392,\n",
    "    reg_lambda=8.769761580128085,\n",
    "    min_child_weight=1.105089752114477,\n",
    "    random_state=42,\n",
    "    force_col_wise=True,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# Optimized XGBoost model\n",
    "# optimized_xgb_model = XGBRegressor(\n",
    "#     n_estimators=541,\n",
    "#     learning_rate=0.03143204336162494,\n",
    "#     max_depth=6,\n",
    "#     subsample=0.8414548026219018,\n",
    "#     colsample_bytree=0.8774468113199907,\n",
    "#     reg_alpha=0.9106427018084773,\n",
    "#     reg_lambda=5.725763474248076,\n",
    "#     min_child_weight=3.6121329951143517,\n",
    "#     gamma=4.644504781492626,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "ensemble = StackingRegressor(estimators=[\n",
    "    ('lgb', Pipeline(steps=[('imputer', imputer), ('regressor', optimized_lgb_model)])),\n",
    "    ('xgb', Pipeline(steps=[('imputer', imputer), ('regressor', XGBRegressor(random_state=42))])),\n",
    "    ('cat', Pipeline(steps=[('imputer', imputer), ('regressor', CatBoostRegressor(random_state=42, silent=True))])),\n",
    "    ('rf', Pipeline(steps=[('imputer', imputer), ('regressor', RandomForestRegressor(random_state=42))])),\n",
    "    ('gb', Pipeline(steps=[('imputer', imputer), ('regressor', GradientBoostingRegressor(random_state=42))]))\n",
    "])\n",
    "\n",
    "Submission = TrainML(ensemble, test)\n",
    "Submission = pd.DataFrame({\n",
    "    'id': sample['id'],\n",
    "    'sii': Submission\n",
    "})\n",
    "\n",
    "Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    },
    {
     "datasetId": 921302,
     "sourceId": 7453542,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
